#!/usr/bin/env python3
"""
MCP ì„œë²„ - tbell.ai_model / eval_session_plan í…Œì´ë¸”ì—ì„œ ì‹¤ì œ ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ëŠ” ì„œë²„
"""

import asyncio
import json
from typing import Any, Dict, Optional, List

from mcp.server import Server, InitializationOptions, NotificationOptions
from mcp.server.stdio import stdio_server
from mcp.types import (
    CallToolResult,
    ListToolsResult,
    Tool,
    TextContent,
)
from app.core.logging import get_logger
from app.crud import mcp as mcp_crud

# MCP ì„œë²„ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
server = Server("ai-model-mcp-server")
logger = get_logger(__name__)


# ===== ë¹„ë™ê¸° ë˜í¼ í•¨ìˆ˜ë“¤ =====
async def fetch_all_models(only_used: bool = False) -> List[Dict[str, Any]]:
    """ai_model í…Œì´ë¸”ì—ì„œ ì „ì²´ ëª¨ë¸ ëª©ë¡ì„ ë¹„ë™ê¸°ë¡œ ì¡°íšŒí•©ë‹ˆë‹¤."""
    return await asyncio.to_thread(mcp_crud.fetch_all_models_sync, only_used)


async def fetch_model_by_name(model_name: str) -> Optional[Dict[str, Any]]:
    """ì§€ì •ëœ ì´ë¦„ì˜ AI ëª¨ë¸ì„ ë¹„ë™ê¸°ë¡œ ì¡°íšŒí•©ë‹ˆë‹¤."""
    return await asyncio.to_thread(mcp_crud.fetch_model_by_name_sync, model_name)


async def fetch_eval_session_stats() -> Dict[str, Any]:
    """í‰ê°€ ì„¸ì…˜ì˜ ìƒíƒœë³„ í†µê³„ë¥¼ ë¹„ë™ê¸°ë¡œ ì¡°íšŒí•©ë‹ˆë‹¤."""
    return await asyncio.to_thread(mcp_crud.fetch_eval_session_stats_sync)


# ===== MCP ë„êµ¬ ì •ì˜ =====
@server.list_tools()
async def list_tools() -> ListToolsResult:
    """ì‚¬ìš© ê°€ëŠ¥í•œ MCP ë„êµ¬ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    tools = [
        # 1. AI ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ë„êµ¬
        Tool(
            name="list_ai_models",
            description="ai_model í…Œì´ë¸”ì˜ ëª¨ë¸ ì „ì²´ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.",
            inputSchema={
                "type": "object",
                "properties": {
                    "only_used": {
                        "type": "boolean",
                        "description": "trueì´ë©´ is_used = true ì¸ ëª¨ë¸ë§Œ ì¡°íšŒí•©ë‹ˆë‹¤.",
                    }
                },
                "required": [],
            },
        ),
        # 2. íŠ¹ì • AI ëª¨ë¸ ì¡°íšŒ ë„êµ¬
        Tool(
            name="get_ai_model_by_name",
            description="model_nameìœ¼ë¡œ íŠ¹ì • AI ëª¨ë¸ í•œ ê°œë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.",
            inputSchema={
                "type": "object",
                "properties": {
                    "model_name": {
                        "type": "string",
                        "description": "ì¡°íšŒí•  ëª¨ë¸ ì´ë¦„ (ai_model.model_name)",
                    }
                },
                "required": ["model_name"],
            },
        ),
        # 3. í‰ê°€ ì„¸ì…˜ í†µê³„ ì¡°íšŒ ë„êµ¬
        Tool(
            name="get_eval_session_stats",
            description=(
                "eval_session_plan í…Œì´ë¸”ì—ì„œ "
                "RUNNING : 'ìˆ˜í–‰ì¤‘' / DONE : 'ìˆ˜í–‰ ì™„ë£Œ' / ERROR : 'ìˆ˜í–‰ ì¤‘ ì˜¤ë¥˜' ìƒíƒœë³„ í‰ê°€ ì„¸ì…˜ ê°œìˆ˜ë¥¼ ì§‘ê³„í•©ë‹ˆë‹¤."
            ),
            inputSchema={
                "type": "object",
                "properties": {},
                "required": [],
            },
        ),
    ]
    return ListToolsResult(tools=tools)


# ===== MCP ë„êµ¬ í˜¸ì¶œ ì²˜ë¦¬ =====
@server.call_tool()
async def call_tool(name: str, arguments: Dict[str, Any]) -> CallToolResult:
    """MCP ë„êµ¬ í˜¸ì¶œì„ ì²˜ë¦¬í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        # 1) AI ëª¨ë¸ ì „ì²´ ëª©ë¡ ì¡°íšŒ
        if name == "list_ai_models":
            only_used = bool(arguments.get("only_used", False))
            models = await fetch_all_models(only_used=only_used)
            text = json.dumps(models, ensure_ascii=False, indent=2)
            return CallToolResult(
                content=[TextContent(type="text", text=f"ai_model ëª©ë¡:\n{text}")]
            )

        # 2) ëª¨ë¸ ì´ë¦„ìœ¼ë¡œ ë‹¨ì¼ ëª¨ë¸ ì¡°íšŒ
        elif name == "get_ai_model_by_name":
            model_name = arguments.get("model_name")
            if not model_name:
                return CallToolResult(
                    content=[
                        TextContent(
                            type="text", text="ì˜¤ë¥˜: model_name ì¸ìê°€ í•„ìš”í•©ë‹ˆë‹¤."
                        )
                    ],
                    isError=True,
                )

            model = await fetch_model_by_name(str(model_name))
            if model is None:
                return CallToolResult(
                    content=[
                        TextContent(
                            type="text",
                            text=f"ì˜¤ë¥˜: model_name='{model_name}' ì¸ AI ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                        )
                    ],
                    isError=True,
                )

            text = json.dumps(model, ensure_ascii=False, indent=2)
            return CallToolResult(
                content=[TextContent(type="text", text=f"AI ëª¨ë¸ ì •ë³´:\n{text}")]
            )

        # 3) í‰ê°€ ì„¸ì…˜ í†µê³„ ì¡°íšŒ
        elif name == "get_eval_session_stats":
            stats = await fetch_eval_session_stats()
            text = json.dumps(stats, ensure_ascii=False, indent=2)
            return CallToolResult(
                content=[
                    TextContent(
                        type="text", text=f"eval_session_plan ìƒíƒœ ì§‘ê³„:\n{text}"
                    )
                ]
            )

        # ë“±ë¡ë˜ì§€ ì•Šì€ ë„êµ¬ ìš”ì²­ ì‹œ
        return CallToolResult(
            content=[
                TextContent(
                    type="text", text=f"ì˜¤ë¥˜: '{name}' ë„êµ¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                )
            ],
            isError=True,
        )

    except Exception as e:
        logger.exception("ë„êµ¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
        return CallToolResult(
            content=[
                TextContent(type="text", text=f"ë„êµ¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            ],
            isError=True,
        )


async def main():
    """MCP ì„œë²„ë¥¼ ì‹œì‘í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜"""
    logger.info("ğŸš€ MCP ì„œë²„(ai_model + eval_session_plan) ì‹œì‘ ì¤‘...")

    async with stdio_server() as (read_stream, write_stream):
        init_options = InitializationOptions(
            server_name="ai-model-mcp-server",
            server_version="0.1.0",
            capabilities=server.get_capabilities(
                notification_options=NotificationOptions(),
                experimental_capabilities={},
            ),
        )

        await server.run(read_stream, write_stream, init_options)

    logger.info("ğŸ›‘ MCP ì„œë²„ ì¢…ë£Œ")


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except Exception as e:
        logger.error(f"âŒ MCP ì„œë²„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
