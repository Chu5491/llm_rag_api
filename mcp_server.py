#!/usr/bin/env python3
"""
MCP ì„œë²„ - tbell.ai_model / eval_session_plan í…Œì´ë¸”ì—ì„œ ì‹¤ì œ ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ëŠ” ì„œë²„ (pg8000 ì‚¬ìš©)
"""

import asyncio
import json
from typing import Any, Dict, Optional, List
from urllib.parse import urlparse

import pg8000
from mcp.server import Server, InitializationOptions, NotificationOptions
from mcp.server.stdio import stdio_server
from mcp.types import (
    CallToolResult,
    ListToolsResult,
    Tool,
    TextContent,
)
from app.core.logging import get_logger
from app.core.config import get_settings

settings = get_settings()
server = Server("ai-model-mcp-server")
logger = get_logger(__name__)

# ===== DB ì„¤ì • =====
DB_DSN = settings.MCP_DB_CON


def parse_pg_dsn(dsn: str) -> Dict[str, Any]:
    """postgresql://user:pass@host:port/db í˜•íƒœ DSNì„ pg8000 connect ì¸ìë¡œ ë³€í™˜"""
    r = urlparse(dsn)
    return {
        "user": r.username,
        "password": r.password,
        "host": r.hostname or "localhost",
        "port": r.port or 5432,
        "database": (r.path or "").lstrip("/") or None,
    }


# ===== ë™ê¸° ì¿¼ë¦¬ë¥¼ asyncì—ì„œ ì“°ê¸° ìœ„í•´ to_threadë¡œ ê°ì‹¸ëŠ” ë™ê¸° í•¨ìˆ˜ë“¤ =====
def _fetch_all_models_sync(only_used: bool = False) -> List[Dict[str, Any]]:
    """ai_model í…Œì´ë¸” ì „ì²´ ëª©ë¡(ì˜µì…˜: only_used) ë™ê¸° ì¡°íšŒ"""
    cfg = parse_pg_dsn(DB_DSN)
    conn = pg8000.connect(**cfg)
    try:
        cur = conn.cursor()
        query = """
            SELECT
                id,
                model_name,
                model_version,
                is_used,
                created_at,
                updated_at
            FROM public.ai_model
        """
        if only_used:
            query += " WHERE is_used = TRUE"
        query += " ORDER BY id ASC"

        cur.execute(query)
        rows = cur.fetchall()
        cols = [desc[0] for desc in cur.description]

        result: List[Dict[str, Any]] = []
        for row in rows:
            r = dict(zip(cols, row))
            result.append(
                {
                    "id": r["id"],
                    "model_name": r["model_name"],
                    "model_version": r.get("model_version"),
                    "is_used": r["is_used"],
                    "created_at": r["created_at"].isoformat()
                    if r.get("created_at")
                    else None,
                    "updated_at": r["updated_at"].isoformat()
                    if r.get("updated_at")
                    else None,
                }
            )
        return result
    finally:
        conn.close()


def _fetch_model_by_name_sync(
    model_name: str,
) -> Optional[Dict[str, Any]]:
    """model_nameìœ¼ë¡œ ai_model ë‹¨ê±´ ë™ê¸° ì¡°íšŒ"""
    cfg = parse_pg_dsn(DB_DSN)
    conn = pg8000.connect(**cfg)
    try:
        cur = conn.cursor()
        query = """
            SELECT
                id,
                model_name,
                model_version,
                is_used,
                created_at,
                updated_at
            FROM public.ai_model
            WHERE model_name = %s
        """
        cur.execute(query, (model_name,))
        row = cur.fetchone()
        if row is None:
            return None

        cols = [d[0] for d in cur.description]
        r = dict(zip(cols, row))
        return {
            "id": r["id"],
            "model_name": r["model_name"],
            "model_version": r.get("model_version"),
            "is_used": r["is_used"],
            "created_at": r["created_at"].isoformat() if r.get("created_at") else None,
            "updated_at": r["updated_at"].isoformat() if r.get("updated_at") else None,
        }
    finally:
        conn.close()


def _fetch_eval_session_stats_sync() -> Dict[str, Any]:
    """
    eval_session_planì—ì„œ ìƒíƒœë³„ ê°œìˆ˜ ì§‘ê³„ ë™ê¸° ì¡°íšŒ.

    RUNNING / DONE / ERROR ê¸°ì¤€ìœ¼ë¡œ ê°œìˆ˜ë¥¼ ë¦¬í„´í•˜ê³ ,
    í˜¹ì‹œ ë‹¤ë¥¸ ìƒíƒœê°€ ìˆìœ¼ë©´ raw í•­ëª©ì— ê·¸ëŒ€ë¡œ í¬í•¨.
    """
    cfg = parse_pg_dsn(DB_DSN)
    conn = pg8000.connect(**cfg)
    try:
        cur = conn.cursor()
        query = """
            SELECT eval_status, COUNT(*) AS cnt
            FROM public.eval_session_plan
            GROUP BY eval_status
        """
        cur.execute(query)
        rows = cur.fetchall()

        # ê¸°ë³¸ê°’ 0ìœ¼ë¡œ ì„¸íŒ…
        counts = {
            "RUNNING": 0,
            "DONE": 0,
            "ERROR": 0,
        }
        raw: List[Dict[str, Any]] = []

        for status, cnt in rows:
            status_str = (status or "").upper()
            raw.append(
                {
                    "eval_status": status,
                    "count": int(cnt),
                }
            )
            if status_str in counts:
                counts[status_str] = int(cnt)

        return {
            "running": counts["RUNNING"],
            "done": counts["DONE"],
            "error": counts["ERROR"],
            "raw": raw,
        }
    finally:
        conn.close()


# ===== async wrapper =====
async def fetch_all_models(only_used: bool = False) -> List[Dict[str, Any]]:
    """ai_model ì „ì²´ ëª©ë¡ async ë˜í•‘"""
    return await asyncio.to_thread(_fetch_all_models_sync, only_used)


async def fetch_model_by_name(
    model_name: str,
) -> Optional[Dict[str, Any]]:
    """model_nameìœ¼ë¡œ ai_model ë‹¨ê±´ async ë˜í•‘"""
    return await asyncio.to_thread(_fetch_model_by_name_sync, model_name)


async def fetch_eval_session_stats() -> Dict[str, Any]:
    """eval_session_plan ìƒíƒœ ì§‘ê³„ async ë˜í•‘"""
    return await asyncio.to_thread(_fetch_eval_session_stats_sync)


# ===== MCP Tools ì •ì˜ =====
@server.list_tools()
async def list_tools() -> ListToolsResult:
    tools = [
        Tool(
            name="list_ai_models",
            description="ai_model í…Œì´ë¸”ì˜ ëª¨ë¸ ì „ì²´ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.",
            inputSchema={
                "type": "object",
                "properties": {
                    "only_used": {
                        "type": "boolean",
                        "description": "trueì´ë©´ is_used = true ì¸ ëª¨ë¸ë§Œ ì¡°íšŒí•©ë‹ˆë‹¤.",
                    }
                },
                "required": [],
            },
        ),
        Tool(
            name="get_ai_model_by_name",
            description="model_nameìœ¼ë¡œ íŠ¹ì • AI ëª¨ë¸ í•œ ê°œë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.",
            inputSchema={
                "type": "object",
                "properties": {
                    "model_name": {
                        "type": "string",
                        "description": "ì¡°íšŒí•  ëª¨ë¸ ì´ë¦„ (ai_model.model_name)",
                    }
                },
                "required": ["model_name"],
            },
        ),
        Tool(
            name="get_eval_session_stats",
            description=(
                "eval_session_plan í…Œì´ë¸”ì—ì„œ "
                "RUNNING : 'ìˆ˜í–‰ì¤‘' / DONE : 'ìˆ˜í–‰ ì™„ë£Œ' / ERROR : 'ìˆ˜í–‰ ì¤‘ ì˜¤ë¥˜' ìƒíƒœë³„ í‰ê°€ ì„¸ì…˜ ê°œìˆ˜ë¥¼ ì§‘ê³„í•©ë‹ˆë‹¤."
            ),
            inputSchema={
                "type": "object",
                "properties": {},
                "required": [],
            },
        ),
    ]
    return ListToolsResult(tools=tools)


# ===== MCP Tool í˜¸ì¶œ ì²˜ë¦¬ =====
@server.call_tool()
async def call_tool(name: str, arguments: Dict[str, Any]) -> CallToolResult:
    try:
        # 1) ai_model ì „ì²´ ë¦¬ìŠ¤íŠ¸
        if name == "list_ai_models":
            only_used = bool(arguments.get("only_used", False))
            models = await fetch_all_models(only_used=only_used)

            text = json.dumps(models, ensure_ascii=False, indent=2)
            return CallToolResult(
                content=[
                    TextContent(
                        type="text",
                        text=f"ai_model ëª©ë¡:\n{text}",
                    )
                ]
            )

        # 2) model_nameìœ¼ë¡œ ai_model ë‹¨ê±´ ì¡°íšŒ
        elif name == "get_ai_model_by_name":
            model_name = arguments.get("model_name")
            if not model_name:
                return CallToolResult(
                    content=[
                        TextContent(
                            type="text",
                            text="ì˜¤ë¥˜: model_name ì¸ìê°€ í•„ìš”í•©ë‹ˆë‹¤.",
                        )
                    ],
                    isError=True,
                )

            model = await fetch_model_by_name(str(model_name))
            if model is None:
                return CallToolResult(
                    content=[
                        TextContent(
                            type="text",
                            text=f"ì˜¤ë¥˜: model_name='{model_name}' ì¸ AI ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                        )
                    ],
                    isError=True,
                )

            text = json.dumps(model, ensure_ascii=False, indent=2)
            return CallToolResult(
                content=[
                    TextContent(
                        type="text",
                        text=f"AI ëª¨ë¸ ì •ë³´:\n{text}",
                    )
                ]
            )

        # 3) eval_session_plan ìƒíƒœë³„ ì¹´ìš´íŠ¸
        elif name == "get_eval_session_stats":
            stats = await fetch_eval_session_stats()
            text = json.dumps(stats, ensure_ascii=False, indent=2)
            return CallToolResult(
                content=[
                    TextContent(
                        type="text",
                        text=f"eval_session_plan ìƒíƒœ ì§‘ê³„:\n{text}",
                    )
                ]
            )

        # ë“±ë¡ë˜ì§€ ì•Šì€ íˆ´
        else:
            return CallToolResult(
                content=[
                    TextContent(
                        type="text",
                        text=f"ì˜¤ë¥˜: '{name}' íˆ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    )
                ],
                isError=True,
            )

    except Exception as e:
        logger.exception("íˆ´ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
        return CallToolResult(
            content=[
                TextContent(
                    type="text",
                    text=f"íˆ´ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                )
            ],
            isError=True,
        )


async def main():
    logger.info("ğŸš€ MCP ì„œë²„(ai_model + eval_session_plan) ì‹œì‘ ì¤‘...")

    async with stdio_server() as (read_stream, write_stream):
        init_options = InitializationOptions(
            server_name="ai-model-mcp-server",
            server_version="0.1.0",
            capabilities=server.get_capabilities(
                notification_options=NotificationOptions(),
                experimental_capabilities={},
            ),
        )

        await server.run(
            read_stream,
            write_stream,
            init_options,
        )

    logger.info("ğŸ›‘ MCP ì„œë²„ ì¢…ë£Œ")


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except Exception as e:
        logger.error(f"âŒ MCP ì„œë²„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
